{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import skimage\n",
    "from skimage import data, measure\n",
    "from skimage.io import imread\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import clear_border\n",
    "\n",
    "from skimage.measure import regionprops\n",
    "from skimage.morphology import closing, square\n",
    "\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "from exp_utils import *\n",
    "from model_utils import *\n",
    "from utils import l2_regularisation\n",
    "\n",
    "\n",
    "\n",
    "from data import *\n",
    "\n",
    "from StitchingDeTr import *\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data process/loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='/media/hmn-mednuc/InternalDisk_1/datasets/GAINED/resampled_croped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loader(dataset,batch_size=10,shuffle=True):\n",
    "    \n",
    "    partition_train_val=[int(len(dataset)*0.8),int(len(dataset)*0.2)+1]\n",
    "    #print(len(dataset))\n",
    "    #print(sum(partition_train_val))\n",
    "    \n",
    "\n",
    "        \n",
    "    train_set,valid_set = random_split(dataset,partition_train_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, num_workers = 0, shuffle=shuffle)\n",
    "    val_loader = DataLoader(valid_set, batch_size=batch_size, num_workers = 0, shuffle=shuffle)\n",
    "\n",
    "#     train_loader = DataLoader(train_set, batch_size=batch_size, num_workers = 0, shuffle=shuffle, pin_memory=torch.cuda.is_available())\n",
    "#     val_loader = DataLoader(valid_set, batch_size=batch_size, num_workers = 0, shuffle=shuffle, pin_memory=torch.cuda.is_available())\n",
    "    return train_loader,val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model def/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HPUnet_torch import HierarchicalProbUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_channels = 24\n",
    "num_convs_per_block = 3\n",
    "default_channels_per_block = (\n",
    "     base_channels,\n",
    "\t2* base_channels,\n",
    "\t 4*base_channels,\n",
    "     8*base_channels,\n",
    "\t 8*base_channels,\n",
    "\t 8*base_channels,\n",
    "\t 8*base_channels,\n",
    "    8*base_channels,\n",
    "8*base_channels)\n",
    "input_channels = tuple([1])+tuple([i for i in default_channels_per_block])\n",
    "\n",
    "channels_per_block = default_channels_per_block\n",
    "down_channels_per_block = tuple([i / 2 for i in default_channels_per_block])\n",
    "#net=Hierarchical_Core(dim=2,input_channels=list(input_channels),channels_per_block=list(channels_per_block),\n",
    "#               down_channels_per_block=list(down_channels_per_block), convs_per_block=3,\n",
    "#               blocks_per_level=3,Posterior=False)\n",
    "\n",
    "#HPUnetscri=StitchingDecoder(dim=2,latent_dims=[1,1,1,1],input_channels=list(input_channels),channels_per_block=list(channels_per_block),num_classes=6,\n",
    "#               down_channels_per_block=list(down_channels_per_block), convs_per_block=3,\n",
    "#               blocks_per_level=3)\n",
    "\n",
    "\n",
    "net=HierarchicalProbUNet(dim=2,latent_dims=[1,1,1,1],input_channels=list(input_channels),channels_per_block=list(channels_per_block),num_classes=2,\n",
    "               down_channels_per_block=list(down_channels_per_block), convs_per_block=3,\n",
    "               blocks_per_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_path = './chkpoint_withgen_with_size256x256_beta1_30epochs'\n",
    "best_model_path = './bestmodel_withgen_with_size256x256_beta1_30epochs.pt'\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "net.to(device)\n",
    "net.train()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4, weight_decay=0)\n",
    "epochs = 30\n",
    "beta=1.0\n",
    "\n",
    "\n",
    "# train_dataset = MRI2DSegmentationDataset(data_dir=data_dir, slice_axis=1,transform=mt_transforms.ToTensor())\n",
    "\n",
    "# data = train_dataset[70]\n",
    "\n",
    "# print(data[\"input\"].shape)\n",
    "# print(data[\"gt\"].shape)\n",
    "# print(data[\"boxes\"])\n",
    "# print(data[\"labels\"])\n",
    "\n",
    "\n",
    "\n",
    "data_dir='/media/hmn-mednuc/InternalDisk_1/datasets/GAINED/resampled_croped/'\n",
    "\n",
    "valid_loss_min=float('inf')\n",
    "\n",
    "# TODO lesy way of capturing the logs, find a more elegant way to capture the logs \n",
    "\n",
    "train_loss,val_loss=[],[]\n",
    "dice_score_train,dice_score_val=[],[]\n",
    "kls_loss_train,kls_loss_val=[],[]\n",
    "recons_loss_train,recons_loss_val=[],[]\n",
    "detection_loss_train,detection_loss_val=[],[]\n",
    "\n",
    "\n",
    "#print(\"zHere\")\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    dataset = MRI2DSegmentationDataset(data_dir=data_dir, slice_axis=1)\n",
    "    train_loader,val_loader=prepare_loader(dataset)\n",
    "\n",
    "    running_train_reconstruction,running_train_kl_loss,running_train_total_loss,running_train_score = [[] for _ in range(4)]\n",
    "\n",
    "    print('Numbers of epoch:{}/{}'.format(epoch+1,epochs))\n",
    "    started = time.time()\n",
    "          \n",
    "    for batch_idx, (train_batch_input , train_batch_gt) in enumerate(train_loader):\n",
    "        #print('Batch idx {}, data shape {}, target shape {}'.format(batch_idx, data.shape, target.shape))\n",
    "        target,data=train_batch_gt.to(device),train_batch_input.to(device)\n",
    "        #targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "\n",
    "\n",
    "        # kl divergence loss/loss_per_level part of the ELBO\n",
    "\n",
    "        kl_loss_per_levels,kl_loss = net.kl_divergence_(target,data)\n",
    "\n",
    "\n",
    "        # binary cross-entropy reconstruction loss part of ELBO\n",
    "\n",
    "        reconstruction = net.reconstruct(target,data,mean=False)\n",
    "        loss_bce = nn.BCEWithLogitsLoss(size_average=False,reduce=False,reduction=None)\n",
    "        criterion_reconstruction = loss_bce(input=reconstruction,target=target)\n",
    "        reconstruction_loss = torch.sum(criterion_reconstruction)\n",
    "\n",
    "\n",
    "        # definition of the ELBO\n",
    "\n",
    "        elbo =  -(reconstruction_loss + beta * kl_loss)\n",
    "        \n",
    "        # regularisation term \n",
    "        \n",
    "        reg_loss = l2_regularisation(net._prior)+l2_regularisation(net._posterior)+l2_regularisation(net._f_comb)\n",
    "\n",
    "        # Total loss that will be used to for back propagete the gradient + regularisation term omit for the DeTr for now \n",
    "\n",
    "        \n",
    "        total_loss = -elbo  + 1e-5*reg_loss \n",
    "        score = batch_dice(F.softmax(net.sample(data,mean=False),dim=1),target)\n",
    "        #running_loss += loss.item() * inputs.size(0) \n",
    "        #print(loss) \n",
    "        optimizer.zero_grad() \n",
    "        total_loss.backward() \n",
    "        optimizer.step() \n",
    "\n",
    "        #print(len(running_train_Detr_loss))\n",
    "        running_train_total_loss.append(total_loss.item())\n",
    "        running_train_kl_loss.append(kl_loss_per_levels)\n",
    "        #print(len(running_train_kl_loss))\n",
    "        running_train_reconstruction.append(reconstruction_loss.item())\n",
    "        running_train_score.append(score.item())\n",
    "\n",
    "        #running_train_score.append(score.item())\n",
    "        \n",
    "        \n",
    "        #print('loss batch: {},Dice score batch: {}, batch_idx: {}'.format(loss.item(),score.item(),batch_idx))\n",
    "        print(' KL divergence loss over one batch: {} ---- Reconstruction loss over one batch: {} ---- Overall loss batch: {} ---- Overall score batch: {} ---- Batch idx: {}'.format(kl_loss.item(),reconstruction_loss.item(),total_loss.item(),score.item(),batch_idx))\n",
    "\n",
    "    else:\n",
    "        running_valid_reconstruction,running_valid_kl_loss,running_valid_total_loss,running_valid_score = [[] for _ in range(4)]\n",
    "          \n",
    "        with torch.no_grad():\n",
    "\n",
    "            for batch_idx, (valid_batch_input, valid_batch_gt) in enumerate(val_loader):\n",
    "                target,data=valid_batch_gt.to(device),valid_batch_input.to(device)\n",
    "\n",
    "\n",
    "                # kl divergence loss/loss_per_level part of the ELBO\n",
    "\n",
    "                kl_loss_per_levels,kl_loss = net.kl_divergence_(target,data)\n",
    "\n",
    "\n",
    "                # binary cross-entropy reconstruction loss part of ELBO\n",
    "\n",
    "                reconstruction = net.reconstruct(target,data,mean=False)\n",
    "                loss_bce = nn.BCEWithLogitsLoss(size_average=False,reduce=False,reduction=None)\n",
    "                criterion_reconstruction = loss_bce(input=reconstruction,target=target)\n",
    "                reconstruction_loss = torch.sum(criterion_reconstruction)\n",
    "\n",
    "\n",
    "                # definition of the ELBO\n",
    "\n",
    "                elbo =  -(reconstruction_loss + beta * kl_loss)\n",
    "                reg_loss = l2_regularisation(net._prior)+l2_regularisation(net._posterior)+l2_regularisation(net._f_comb)\n",
    "\n",
    "                # Total loss that will be used to for nack propagete the gradient + regularisation term omit for the DeTr for now \n",
    "                total_loss = -elbo + 1e-5*reg_loss \n",
    "\n",
    "                score = batch_dice(F.softmax(net.sample(data,mean=False),dim=1),target)\n",
    "\n",
    " \n",
    "                running_valid_total_loss.append(total_loss.item())\n",
    "                running_valid_kl_loss.append(kl_loss_per_levels)\n",
    "                running_valid_reconstruction.append(reconstruction_loss.item())\n",
    "                running_valid_score.append(score.item())\n",
    "        \n",
    "    epoch_train_loss,epoch_train_kl,epoch_train_score,epoch_train_reconstruction = np.mean(running_train_total_loss),np.mean(running_train_kl_loss,axis=0),np.mean(running_train_score),np.mean(running_train_reconstruction)\n",
    "    print('Train total loss epoch : {} Dice score epoch : {}'.format(epoch_train_loss,epoch_train_score))\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    dice_score_train.append(epoch_train_score)\n",
    "    kls_loss_train.append(epoch_train_kl)\n",
    "    recons_loss_train.append(epoch_train_reconstruction)\n",
    "\n",
    "    epoch_val_loss,epoch_val_kl,epoch_val_score,epoch_val_reconstruction = np.mean(running_valid_total_loss),np.mean(running_valid_kl_loss,axis=0),np.mean(running_valid_score),np.mean(running_valid_reconstruction)\n",
    "    print('Valid total loss epoch: {} Dice score epoch : {}'.format(epoch_val_loss,epoch_val_score))\n",
    "    val_loss.append(epoch_val_loss)\n",
    "    dice_score_val.append(epoch_val_score)\n",
    "    kls_loss_val.append(epoch_val_kl)\n",
    "    recons_loss_val.append(epoch_val_reconstruction)\n",
    "          \n",
    "    checkpoint = {'epoch': epoch +1,\n",
    "                  'valid_loss_min':epoch_val_loss,\n",
    "                  'state_dict':net.state_dict(),\n",
    "                  'optimizer':optimizer.state_dict(),\n",
    "        \n",
    "    }\n",
    "    save_ckp(checkpoint, False,checkpoint_path,best_model_path)\n",
    "     \n",
    "    if epoch_val_loss <= valid_loss_min:\n",
    "          print('Validation loss decreased ({:.6f} =======> {:.6f}). Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
    "          \n",
    "          save_ckp(checkpoint, True,checkpoint_path,best_model_path)\n",
    "          valid_loss_min = epoch_val_loss\n",
    "          \n",
    "    time_passed = time.time() - started\n",
    "    print('{:.0f}m {:.0f}s'.format(time_passed//60, time_passed%60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_path = './chkpoint_withgen_with_detection_zer_test'\n",
    "best_model_path = './bestmodel_withgen_with_detection_zer_test.pt'\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "net.to(device)\n",
    "net.train()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4, weight_decay=0)\n",
    "epochs = 30\n",
    "beta=1.0\n",
    "\n",
    "\n",
    "# train_dataset = MRI2DSegmentationDataset(data_dir=data_dir, slice_axis=1,transform=mt_transforms.ToTensor())\n",
    "\n",
    "# data = train_dataset[70]\n",
    "\n",
    "# print(data[\"input\"].shape)\n",
    "# print(data[\"gt\"].shape)\n",
    "# print(data[\"boxes\"])\n",
    "# print(data[\"labels\"])\n",
    "\n",
    "\n",
    "\n",
    "data_dir='/media/hmn-mednuc/InternalDisk_1/datasets/GAINED/resampled_croped/'\n",
    "\n",
    "valid_loss_min=float('inf')\n",
    "\n",
    "# TODO lesy way of capturing the logs, find a more elegant way to capture the logs \n",
    "\n",
    "train_loss,val_loss=[],[]\n",
    "dice_score_train,dice_score_val=[],[]\n",
    "kls_loss_train,kls_loss_val=[],[]\n",
    "recons_loss_train,recons_loss_val=[],[]\n",
    "detection_loss_train,detection_loss_val=[],[]\n",
    "\n",
    "\n",
    "#print(\"zHere\")\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    dataset = MRI2DSegmentationDataset(data_dir=data_dir, slice_axis=1)\n",
    "    train_loader,val_loader=prepare_loader(dataset)\n",
    "\n",
    "    running_train_Detr_loss,running_train_reconstruction,running_train_kl_loss,running_train_total_loss,running_train_score = [[] for _ in range(5)]\n",
    "\n",
    "    print('Numbers of epoch:{}/{}'.format(epoch+1,epochs))\n",
    "    started = time.time()\n",
    "          \n",
    "    for batch_idx, (train_batch_input , train_batch_gt , targets) in enumerate(train_loader):\n",
    "        #print('Batch idx {}, data shape {}, target shape {}'.format(batch_idx, data.shape, target.shape))\n",
    "        target,data=train_batch_gt.to(device),train_batch_input.to(device)\n",
    "        _,outputs=net.sample_and_detect(data,mean=True,z_q=None)\n",
    "        #targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        targets = [{\"labels\": l.to(device),\"boxes\":b.to(device)} for l,b in zip(targets[\"labels\"],targets[\"boxes\"])]\n",
    "        \n",
    "        # loss from the DeTr '3 losses'\n",
    "        \n",
    "        loss_dict = criterion(outputs, targets)\n",
    "        #print(loss_dict)\n",
    "        weight_dict = criterion.weight_dict\n",
    "        losses_detr = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "        #print(loss_dict)\n",
    "\n",
    "\n",
    "        # kl divergence loss/loss_per_level part of the ELBO\n",
    "\n",
    "        kl_loss_per_levels,kl_loss = net.kl_divergence_(target,data)\n",
    "\n",
    "\n",
    "        # binary cross-entropy reconstruction loss part of ELBO\n",
    "\n",
    "        reconstruction = net.reconstruct(target,data,mean=False)\n",
    "        loss_bce = nn.BCEWithLogitsLoss(size_average=False,reduce=False,reduction=None)\n",
    "        criterion_reconstruction = loss_bce(input=reconstruction,target=target)\n",
    "        reconstruction_loss = torch.sum(criterion_reconstruction)\n",
    "\n",
    "\n",
    "        # definition of the ELBO\n",
    "\n",
    "        elbo =  -(reconstruction_loss + beta * kl_loss)\n",
    "        reg_loss = l2_regularisation(net._prior)+l2_regularisation(net._posterior)+l2_regularisation(net._f_comb)\n",
    "\n",
    "        # Total loss that will be used to for nack propagete the gradient + regularisation term omit for the DeTr for now \n",
    "\n",
    "        \n",
    "        total_loss = -elbo + losses_detr + 1e-5*reg_loss \n",
    "        score = batch_dice(F.softmax(net.sample(data,mean=False),dim=1),target)\n",
    "        #running_loss += loss.item() * inputs.size(0) \n",
    "        #print(loss) \n",
    "        optimizer.zero_grad() \n",
    "        total_loss.backward() \n",
    "        optimizer.step() \n",
    "\n",
    "        running_train_Detr_loss.append([loss_dict[k].item() * weight_dict[k] for k in loss_dict.keys() if k in weight_dict])\n",
    "        #print(len(running_train_Detr_loss))\n",
    "        running_train_total_loss.append(total_loss.item())\n",
    "        running_train_kl_loss.append(kl_loss_per_levels)\n",
    "        #print(len(running_train_kl_loss))\n",
    "        running_train_reconstruction.append(reconstruction_loss.item())\n",
    "        running_train_score.append(score.item())\n",
    "\n",
    "        #running_train_score.append(score.item())\n",
    "        \n",
    "        \n",
    "        #print('loss batch: {},Dice score batch: {}, batch_idx: {}'.format(loss.item(),score.item(),batch_idx))\n",
    "        print('Loss DeTr loss over one batch: {} ---- KL divergence loss over one batch: {} ---- Reconstruction loss over one batch: {} ---- Overall loss batch: {} ---- Overall score batch: {} ---- Batch idx: {}'.format(losses_detr.item(),kl_loss.item(),reconstruction_loss.item(),total_loss.item(),score.item(),batch_idx))\n",
    "\n",
    "    else:\n",
    "        running_valid_Detr_loss,running_valid_reconstruction,running_valid_kl_loss,running_valid_total_loss,running_valid_score = [[] for _ in range(5)]\n",
    "          \n",
    "        with torch.no_grad():\n",
    "\n",
    "            for batch_idx, (valid_batch_input , valid_batch_gt , targets) in enumerate(val_loader):\n",
    "                target,data=valid_batch_gt.to(device),valid_batch_input.to(device)\n",
    "                _,outputs=net.sample_and_detect(data,mean=True,z_q=None)\n",
    "                #targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "                targets = [{\"labels\": l.to(device),\"boxes\":b.to(device)} for l,b in zip(targets[\"labels\"],targets[\"boxes\"])]\n",
    "                \n",
    "                # loss from the DeTr '3 losses'\n",
    "                \n",
    "                loss_dict = criterion(outputs, targets)\n",
    "                print(loss_dict)\n",
    "                weight_dict = criterion.weight_dict\n",
    "                losses_detr = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "\n",
    "\n",
    "                # kl divergence loss/loss_per_level part of the ELBO\n",
    "\n",
    "                kl_loss_per_levels,kl_loss = net.kl_divergence_(target,data)\n",
    "\n",
    "\n",
    "                # binary cross-entropy reconstruction loss part of ELBO\n",
    "\n",
    "                reconstruction = net.reconstruct(target,data,mean=False)\n",
    "                loss_bce = nn.BCEWithLogitsLoss(size_average=False,reduce=False,reduction=None)\n",
    "                criterion_reconstruction = loss_bce(input=reconstruction,target=target)\n",
    "                reconstruction_loss = torch.sum(criterion_reconstruction)\n",
    "\n",
    "\n",
    "                # definition of the ELBO\n",
    "\n",
    "                elbo =  -(reconstruction_loss + beta * kl_loss)\n",
    "                reg_loss = l2_regularisation(net._prior)+l2_regularisation(net._posterior)+l2_regularisation(net._f_comb)\n",
    "\n",
    "                # Total loss that will be used to for nack propagete the gradient + regularisation term omit for the DeTr for now \n",
    "                total_loss = -elbo + losses_detr + 1e-5*reg_loss \n",
    "\n",
    "                score = batch_dice(F.softmax(net.sample(data,mean=False),dim=1),target)\n",
    "\n",
    " \n",
    "                running_valid_Detr_loss.append([loss_dict[k].item() * weight_dict[k] for k in loss_dict.keys() if k in weight_dict])\n",
    "                #print(len(running_valid_Detr_loss[0]))\n",
    "                running_valid_total_loss.append(total_loss.item())\n",
    "                running_valid_kl_loss.append(kl_loss_per_levels)\n",
    "                running_valid_reconstruction.append(reconstruction_loss.item())\n",
    "                running_valid_score.append(score.item())\n",
    "        \n",
    "    epoch_train_loss,epoch_train_kl,epoch_train_score,epoch_train_reconstruction,epoch_train_detr = np.mean(running_train_total_loss),np.mean(running_train_kl_loss,axis=0),np.mean(running_train_score),np.mean(running_train_reconstruction),np.mean(running_train_Detr_loss,axis=0)\n",
    "    print('Train total loss epoch : {} Dice score epoch : {}'.format(epoch_train_loss,epoch_train_score))\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    dice_score_train.append(epoch_train_score)\n",
    "    kls_loss_train.append(epoch_train_kl)\n",
    "    recons_loss_train.append(epoch_train_reconstruction)\n",
    "    detection_loss_train.append(epoch_train_detr)\n",
    "\n",
    "    epoch_val_loss,epoch_val_kl,epoch_val_score,epoch_val_reconstruction,epoch_val_detr = np.mean(running_valid_total_loss),np.mean(running_valid_kl_loss,axis=0),np.mean(running_valid_score),np.mean(running_valid_reconstruction),np.mean(running_valid_Detr_loss,axis=0)\n",
    "    print('Valid total loss epoch: {} Dice score epoch : {}'.format(epoch_val_loss,epoch_val_score))\n",
    "    val_loss.append(epoch_val_loss)\n",
    "    dice_score_val.append(epoch_val_score)\n",
    "    kls_loss_val.append(epoch_val_kl)\n",
    "    recons_loss_val.append(epoch_val_reconstruction)\n",
    "    detection_loss_val.append(epoch_val_detr)\n",
    "          \n",
    "    checkpoint = { 'epoch': epoch +1,\n",
    "                  'valid_loss_min':epoch_val_loss,\n",
    "                  'state_dict':net.state_dict(),\n",
    "                  'optimizer':optimizer.state_dict(),\n",
    "        \n",
    "    }\n",
    "    save_ckp(checkpoint, False,checkpoint_path,best_model_path)\n",
    "     \n",
    "    if epoch_val_loss <= valid_loss_min:\n",
    "          print('Validation loss decreased ({:.6f} =======> {:.6f}). Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
    "          \n",
    "          save_ckp(checkpoint, True,checkpoint_path,best_model_path)\n",
    "          valid_loss_min = epoch_val_loss\n",
    "          \n",
    "    time_passed = time.time() - started\n",
    "    print('{:.0f}m {:.0f}s'.format(time_passed//60, time_passed%60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checkpoint_path = './chkpoint_withgen_valid'\n",
    "# best_model_path = './bestmodel_withgen_valid.pt'\n",
    "# device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "# net.to(device)\n",
    "# net.train()\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=1e-4, weight_decay=0)\n",
    "# epochs = 20\n",
    "\n",
    "# valid_loss_min=float('inf')\n",
    "# train_loss,val_loss=[],[]\n",
    "# dice_score_train,dice_score_val=[],[]\n",
    "\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "    \n",
    "#     dataset = MRI2DSegmentationDataset(data_dir=data_dir, slice_axis=1)\n",
    "#     train_loader,val_loader=prepare_loader(dataset)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     running_train_loss = []\n",
    "#     running_train_score = []\n",
    "#     print('Numbers of epoch:{}/{}'.format(epoch+1,epochs))\n",
    "#     started = time.time()\n",
    "          \n",
    "#     for batch_idx, train_batch in enumerate(train_loader):\n",
    "#         #print('Batch idx {}, data shape {}, target shape {}'.format(batch_idx, data.shape, target.shape))\n",
    "#         target,data=train_batch['gt'].to(device),train_batch['input'].to(device)\n",
    "#         elbo = net.elbo(target,data)\n",
    "#         reg_loss = l2_regularisation(net._prior)+l2_regularisation(net._posterior)+l2_regularisation(net._f_comb)\n",
    "#         loss = -elbo + 1e-5*reg_loss\n",
    "#         score = batch_dice(F.softmax(net.sample(data,mean=False),dim=1),target)\n",
    "#         #running_loss += loss.item() * inputs.size(0) \n",
    "#         #print(loss) \n",
    "#         optimizer.zero_grad() \n",
    "#         loss.backward() \n",
    "#         optimizer.step() \n",
    "#         running_train_loss.append(loss.item())\n",
    "#         running_train_score.append(score.item())\n",
    "#         print('loss batch: {},Dice score batch: {}, batch_idx: {}'.format(loss.item(),score.item(),batch_idx))\n",
    "#     else:\n",
    "#         running_val_loss=[]\n",
    "#         running_val_score=[]\n",
    "          \n",
    "#         with torch.no_grad():\n",
    "#             for valid_batch in val_loader:\n",
    "#                 target,data=valid_batch['gt'].to(device),valid_batch['input'].to(device)\n",
    "#                 elbo = net.elbo(target.to(device),data.to(device))\n",
    "#                 reg_loss = l2_regularisation(net._prior)+l2_regularisation(net._posterior)+l2_regularisation(net._f_comb)\n",
    "#                 loss = -elbo + 1e-5*reg_loss\n",
    "#                 score = batch_dice(F.softmax(net.sample(data,mean=False),dim=1),target)\n",
    "#                 running_val_loss.append(loss.item())\n",
    "#                 running_val_score.append(score.item())\n",
    "        \n",
    "#     epoch_train_loss,epoch_train_score = np.mean(running_train_loss),np.mean(running_train_score)\n",
    "#     print('Train loss epoch : {} Dice score epoch : {}'.format(epoch_train_loss,epoch_train_score))\n",
    "#     train_loss.append(epoch_train_loss)\n",
    "#     dice_score_train.append(epoch_train_score)\n",
    "        \n",
    "#     epoch_val_loss,epoch_val_score = np.mean(running_val_loss),np.mean(running_val_score)\n",
    "#     print('Valid loss epoch: {} Dice score epoch : {}'.format(epoch_val_loss,epoch_val_score))\n",
    "#     val_loss.append(epoch_val_loss)\n",
    "#     dice_score_val.append(epoch_val_score)\n",
    "          \n",
    "#     checkpoint = { 'epoch': epoch +1,\n",
    "#                   'valid_loss_min':epoch_val_loss,\n",
    "#                   'state_dict':net.state_dict(),\n",
    "#                   'optimizer':optimizer.state_dict(),\n",
    "        \n",
    "#     }\n",
    "#     save_ckp(checkpoint, False,checkpoint_path,best_model_path)\n",
    "     \n",
    "#     if epoch_val_loss <= valid_loss_min:\n",
    "#           print('Validation loss decreased ({:.6f} =======> {:.6f}). Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
    "          \n",
    "#           save_ckp(checkpoint, True,checkpoint_path,best_model_path)\n",
    "#           valid_loss_min = epoch_val_loss\n",
    "          \n",
    "#     time_passed = time.time() - started\n",
    "#     print('{:.0f}m {:.0f}s'.format(time_passed//60, time_passed%60))\n",
    "# #net.eval()\n",
    "# #sample_1 = net.sample(torch.from_numpy(all_pt_img[25550][np.newaxis][np.newaxis]/100).cuda(),mean=True,z_q=None)\n",
    "# #sample_2 = net.sample(torch.from_numpy(all_pt_img[25550][np.newaxis]/100).cuda(),mean=True,z_q=None)\n",
    "\n",
    "# # print(sample,sample.shape,\"Sample shape\")\n",
    "# # prekd = torch.argmax(sample,axis=1)\n",
    "# # print(pred,pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loss,val_loss=[],[]\n",
    "# dice_score_train,dice_score_val=[],[]\n",
    "# kls_loss_train,kls_loss_val=[],[]\n",
    "# recons_loss_train,recons_loss_val=[],[]\n",
    "# detection_loss_train,detection_loss_val=[],[]\n",
    "\n",
    "\n",
    "training_logs = {\"train_loss\": train_loss, \"dice_score_train\": dice_score_train,\"kls_loss_train\":kls_loss_train,\"recons_loss_train\":recons_loss_train}\n",
    "\n",
    "training_file = open(\"training_logs_run_128128Beta1_epochs60.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(training_logs, training_file)\n",
    "\n",
    "training_file.close()\n",
    "\n",
    "\n",
    "#validation_logs = {\"val_loss\": val_loss, \"dice_score_val\": dice_score_val,\"kls_loss_train\":kls_loss_val,\"recons_loss_val\":recons_loss_val,\"detection_loss_val\":detection_loss_val}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_logs = {\"val_loss\": val_loss, \"dice_score_val\": dice_score_val,\"kls_loss_train\":kls_loss_val,\"recons_loss_val\":recons_loss_val}\n",
    "\n",
    "validation_file = open(\"validation_logs_128128Beta1_epochs60.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(validation_logs, validation_file)\n",
    "\n",
    "validation_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = './chkpoint_withgen_with_size128x128_beta1_60epochs'\n",
    "best_model_path = './bestmodel_withgen_with_size128x128_beta1_60epochs.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path=r\"C:\\Users\\youve\\Dossier Thése\\model_chkpointbest\"\n",
    "best_model_path =\"bestmodel_withgen_valid.pt\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4, weight_decay=0)\n",
    "model=HierarchicalProbUNet(dim=2,latent_dims=[1,1,1,1],input_channels=list(input_channels),channels_per_block=list(channels_per_block),num_classes=2,\n",
    "               down_channels_per_block=list(down_channels_per_block), convs_per_block=3,\n",
    "               blocks_per_level=3)\n",
    "#model, optimizer, start_epoch, valid_loss_min = load_ckp(checkpoint_path, model, optimizer)\n",
    "model, optimizer, start_epoch, valid_loss_min = load_ckp(best_model_path, model, optimizer)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = model._prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=r'C:\\GAINED\\resampled_croped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_test(slices):\n",
    "    test_mask_img=[]\n",
    "    for path in mask_path[slices[0]:slices[1]]:\n",
    "        mask_sitk=sitk.ReadImage(path)\n",
    "        masks_np=sitk.GetArrayFromImage(mask_sitk)\n",
    "        for i in range(masks_np.shape[1]):\n",
    "            test_mask_img.append(masks_np[:,i,:])\n",
    "\n",
    "\n",
    "    test_pt_img=[]\n",
    "    for path in pt_path[slices[0]:slices[1]]:\n",
    "        img_sitk=sitk.ReadImage(path)\n",
    "        img_np=sitk.GetArrayFromImage(img_sitk)\n",
    "        for i in range(img_np.shape[1]):\n",
    "            test_pt_img.append(img_np[:,i,:])\n",
    "    \n",
    "    return test_pt_img,test_mask_img\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find nice slice to show "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pt_img,test_mask_img=image_to_test([100,120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_mask_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_slices = []\n",
    "for ary in test_mask_img:\n",
    "    count_zero = (ary == 0).sum()\n",
    "    unique, counts = np.unique(ary, return_counts=True)\n",
    "    p=counts[1:].sum()/count_zero\n",
    "    good_slices.append(p)\n",
    "    #print(dict(zip(unique, counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dict(zip(good_slices,range(len(test_mask_img))))\n",
    "best_slices_sorted={k: v for k, v in sorted(x.items(), key=lambda item: float(item[0]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_slices_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_pt_img[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_mask_img[310])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=2500\n",
    "desired_shape=(256,256)\n",
    "n_classes=2\n",
    "npa_pet=padding(desired_shape,test_pt_img[i])[np.newaxis,np.newaxis]\n",
    "npa_pet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=12\n",
    "n_classes=2\n",
    "npa_pet=test_pt_img[i][np.newaxis,np.newaxis]\n",
    "npa_pet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=2\n",
    "true_mask = (test_mask_img[i]>= 1).astype(np.int)\n",
    "pad_true_mask = padding(desired_shape,true_mask).astype(np.int)\n",
    "#y_ohe = one_hot_encoding(true_mask,n_classes)[np.newaxis]\n",
    "\n",
    "y_ohe = one_hot_encoding(pad_true_mask,n_classes)[np.newaxis]\n",
    "y_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npa_pet/=100\n",
    "# image = torch.from_numpy(npa_pet).float()\n",
    "# mask = torch.from_numpy(y_ohe).float()\n",
    "# reconstruction=model.reconstruct(mask.to(device),image.to(device),mean=True)\n",
    "# sample_full,detection_full=model.sample_and_detect(image.to(device))\n",
    "# sample_local,detection_local=model.sample_and_detect(image.to(device), mean=[1, 1, 1, 0])\n",
    "# sample_global,detection_global=model.sample_and_detect(image.to(device), mean=[0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npa_pet/=100\n",
    "image = torch.from_numpy(npa_pet).float()\n",
    "mask = torch.from_numpy(y_ohe).float()\n",
    "image_ = image.to(device)\n",
    "reconstruction=model.reconstruct(mask.to(device),image.to(device),mean=True)\n",
    "sample_full=model.sample(image.to(device))\n",
    "sample_local=model.sample(image.to(device), mean=[1, 1, 1, 0])\n",
    "sample_global=model.sample(image.to(device), mean=[0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = model._prior(image_,mean=False, z_q=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_latent = prior[\"used_latents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_local=torch.argmax(sample_local,axis=1)\n",
    "pred_local=pred_local.clone().cpu().detach().numpy()\n",
    "\n",
    "pred_global=torch.argmax(sample_global,axis=1)\n",
    "pred_global=pred_global.clone().cpu().detach().numpy()\n",
    "\n",
    "pred_full=torch.argmax(sample_full,axis=1)\n",
    "pred_full=pred_full.clone().cpu().detach().numpy()\n",
    "\n",
    "pred_reconstruction=torch.argmax(reconstruction,axis=1)\n",
    "pred_reconstruction=pred_reconstruction.clone().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pred_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.subplot(1,6,1)\n",
    "plt.title(\"TEP\")\n",
    "plt.imshow(test_pt_img[i])\n",
    "\n",
    "\n",
    "plt.subplot(1,6,2)\n",
    "plt.title(\"MASK\")\n",
    "plt.imshow(true_mask)\n",
    "\n",
    "plt.subplot(1,6,3)\n",
    "plt.title(\"sample_full\")\n",
    "plt.imshow(pred_full[0])\n",
    "\n",
    "plt.subplot(1,6,4)\n",
    "plt.title(\"sample_local\")\n",
    "plt.imshow(pred_local[0])\n",
    "\n",
    "plt.subplot(1,6,5)\n",
    "plt.title(\"sample_global\")\n",
    "plt.imshow(pred_global[0])\n",
    "\n",
    "plt.subplot(1,6,6)\n",
    "plt.title(\"reconstruction\")\n",
    "plt.imshow(pred_reconstruction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_sample=30\n",
    "# samples=[]\n",
    "# for i in range(num_sample):\n",
    "#     sample,_=model.sample_and_detect(image.to(device))\n",
    "#     pred=sample.clone().cpu().detach().numpy()\n",
    "#     samples.append(pred)\n",
    "\n",
    "# samples_global=[]\n",
    "# for i in range(num_sample):\n",
    "#     sample,_=model.sample_and_detect(image.to(device), mean=[0, 1, 1, 1])\n",
    "#     pred=sample.clone().cpu().detach().numpy()\n",
    "#     samples_global.append(pred)\n",
    "\n",
    "\n",
    "# samples_local=[]\n",
    "# for i in range(num_sample):\n",
    "#     sample,_=model.sample_and_detect(image.to(device), mean=[1, 1, 1, 0])\n",
    "#     pred=sample.clone().cpu().detach().numpy()\n",
    "#     samples_local.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample=30\n",
    "samples=[]\n",
    "for i in range(num_sample):\n",
    "    sample=model.sample(image.to(device))\n",
    "    pred=sample.clone().cpu().detach().numpy()\n",
    "    samples.append(pred)\n",
    "\n",
    "samples_global=[]\n",
    "for i in range(num_sample):\n",
    "    sample=model.sample(image.to(device), mean=[0, 1, 1, 1])\n",
    "    pred=sample.clone().cpu().detach().numpy()\n",
    "    samples_global.append(pred)\n",
    "\n",
    "\n",
    "samples_local=[]\n",
    "for i in range(num_sample):\n",
    "    sample=model.sample(image.to(device), mean=[1, 1, 1, 0])\n",
    "    pred=sample.clone().cpu().detach().numpy()\n",
    "    samples_local.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=torch.from_numpy(np.array(samples_local))\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sm=torch.sigmoid(samples)\n",
    "sample_sm.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=torch.argmax(sample_sm,axis=2)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pred.clone().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std=np.std(pred,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std=100*std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=np.mean(pred,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(std[0])\n",
    "plt.title(\"std images\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(mean[0])\n",
    "plt.title(\"mean images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    plt.imshow(pred[i,0,:,:],cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_local=torch.from_numpy(np.array(samples_local))\n",
    "samples_local.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sm=torch.sigmoid(samples_local)\n",
    "sample_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=torch.argmax(sample_sm,axis=2)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pred.clone().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.imshow(pred[i,0,:,:])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = nib.load(pt_path[1])\n",
    "image = image.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans=transforms.Compose([transforms.Pad((128,0,0,0), fill=0, padding_mode='constant'),\n",
    "   transforms.ToTensor(),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=trans(pet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_np=test.clone().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import MRI2DSegmentationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans={'inputs':transforms.Compose(\n",
    "     [transforms.ToPILImage(mode='LA'), transforms.Pad((0,0,0,128), fill=0, padding_mode='constant'),transforms.ToTensor(),]),\n",
    "    \n",
    "     'mask':transforms.Compose(\n",
    "     [transforms.ToPILImage(mode='L'), transforms.Pad((0,0,0,128), fill=0, padding_mode='constant'),transforms.ToTensor(),])}\n",
    "train_dataset = MRI2DSegmentationDataset(data_dir,cache=True,slice_axis=1,transform=trans)\n",
    "#train_dataset = MRI2DSegmentationDataset(data_dir,transform=trans)\n",
    "#train_dataset.__getitem__(55)\n",
    "\n",
    "set_data=train_dataset[0]\n",
    "print(set_data['input'].shape)\n",
    "print(set_data['gt'].shape)\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = set_data['input'].clone().cpu().detach().numpy()\n",
    "mask = set_data['gt'].clone().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(data[0])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import collections\n",
    "\n",
    "\n",
    "#from medicaltorch import datasets as mt_datasets\n",
    "from medicaltorch import transforms as mt_transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import glob\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torch._six import string_classes, int_classes\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "data_dir='/media/hmn-mednuc/InternalDisk_1/datasets/GAINED/resampled_croped/'\n",
    "\n",
    "def get_path_modality_and_mask(data_dir):\n",
    "    \n",
    "    ls_idx_pet = list(map(lambda x:x.split('/')[-1].split('_')[0] , glob.glob(data_dir + 'PET0/*00001.nii*')))\n",
    "    ls_idx_mask = list(np.unique(np.array(list(map(lambda x:x.split('/')[-1][:14], glob.glob(data_dir + 'PET0_mask*/*nii*'))))))\n",
    "    ls_ids = list(set(ls_idx_pet).intersection(set(ls_idx_mask)))\n",
    "        \n",
    "    pt_path=[os.path.join(data_dir,'PET0',ids+'_00001.nii') for ids in ls_ids]\n",
    "    mask_list = os.path\n",
    "    \n",
    "    mask_path=[os.path.join(data_dir,'PET0_masks',ids+'_mask.nii') for ids in ls_ids]\n",
    "    \n",
    "    \n",
    "    return pt_path,mask_path\n",
    "\n",
    "\n",
    "def padding(desired_shape,npa,value=0):\n",
    "\n",
    "    if value==0:\n",
    "        new_npa=np.zeros(desired_shape)\n",
    "    else:\n",
    "        new_npa=np.zeros(desired_shape)+value\n",
    "\n",
    "    new_npa[:npa.shape[0],:npa.shape[1]] = npa\n",
    "\n",
    "    return new_npa\n",
    "\n",
    "\n",
    "def one_hot_encoding(y,n_classes):\n",
    "    \n",
    "    dim = len(y.shape)\n",
    "    if dim == 2:\n",
    "        one_hot = np.zeros((n_classes,y.shape[0], y.shape[1]))\n",
    "    if dim == 3:\n",
    "        one_hot = np.zeros((n_classes,y.shape[0], y.shape[1],y.shape[2]))\n",
    "    for i,unique_value in enumerate(np.unique(y)):\n",
    "        one_hot[i,:][y == unique_value] = 1\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "\n",
    "class SegmentationPair2D(object):\n",
    "    \"\"\"This class is used to build 2D segmentation datasets. It represents\n",
    "    a pair of of two data volumes (the input data and the ground truth data).\n",
    "\n",
    "    :param input_filename: the input filename (supported by nibabel).\n",
    "    :param gt_filename: the ground-truth filename.\n",
    "    :param cache: if the data should be cached in memory or not.\n",
    "    :param canonical: canonical reordering of the volume axes.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_filename, gt_filename, cache=True,\n",
    "                 canonical=False):\n",
    "        self.input_filename = input_filename\n",
    "        self.gt_filename = gt_filename\n",
    "        self.canonical = canonical\n",
    "        self.cache = cache\n",
    "\n",
    "        self.input_handle = nib.load(self.input_filename)\n",
    "\n",
    "        # Unlabeled data (inference time)\n",
    "        if self.gt_filename is None:\n",
    "            self.gt_handle = None\n",
    "        else:\n",
    "            self.gt_handle = nib.load(self.gt_filename)\n",
    "\n",
    "        if len(self.input_handle.shape) > 3:\n",
    "            raise RuntimeError(\"4-dimensional volumes not supported.\")\n",
    "\n",
    "        # Sanity check for dimensions, should be the same\n",
    "        input_shape, gt_shape = self.get_pair_shapes()\n",
    "\n",
    "        if self.gt_handle is not None:\n",
    "            if not np.allclose(input_shape, gt_shape):\n",
    "                raise RuntimeError('Input and ground truth with different dimensions.')\n",
    "\n",
    "        if self.canonical:\n",
    "            self.input_handle = nib.as_closest_canonical(self.input_handle)\n",
    "\n",
    "            # Unlabeled data\n",
    "            if self.gt_handle is not None:\n",
    "                self.gt_handle = nib.as_closest_canonical(self.gt_handle)\n",
    "\n",
    "    def get_pair_shapes(self):\n",
    "        \"\"\"Return the tuple (input, ground truth) representing both the input\n",
    "        and ground truth shapes.\"\"\"\n",
    "        input_shape = self.input_handle.header.get_data_shape()\n",
    "\n",
    "        # Handle unlabeled data\n",
    "        if self.gt_handle is None:\n",
    "            gt_shape = None\n",
    "        else:\n",
    "            gt_shape = self.gt_handle.header.get_data_shape()\n",
    "\n",
    "        return input_shape, gt_shape\n",
    "\n",
    "    def get_pair_data(self):\n",
    "        \"\"\"Return the tuble (input, ground truth) with the data content in\n",
    "        numpy array.\"\"\"\n",
    "        cache_mode = 'fill' if self.cache else 'unchanged'\n",
    "        input_data = self.input_handle.get_fdata(cache_mode, dtype=np.float32)\n",
    "\n",
    "        # Handle unlabeled data\n",
    "        if self.gt_handle is None:\n",
    "            gt_data = None\n",
    "        else:\n",
    "            gt_data = self.gt_handle.get_fdata(cache_mode, dtype=np.float32)\n",
    "        \n",
    " \n",
    "        return input_data, gt_data\n",
    "\n",
    "    def get_pair_slice(self, slice_index, slice_axis=2):\n",
    "        \"\"\"Return the specified slice from (input, ground truth).\n",
    "\n",
    "        :param slice_index: the slice number.\n",
    "        :param slice_axis: axis to make the slicing.\n",
    "        \"\"\"\n",
    "        if self.cache:\n",
    "            input_dataobj, gt_dataobj = self.get_pair_data()\n",
    "        else:\n",
    "            # use dataobj to avoid caching\n",
    "            input_dataobj = self.input_handle.dataobj\n",
    "\n",
    "            if self.gt_handle is None:\n",
    "                gt_dataobj = None\n",
    "            else:\n",
    "                gt_dataobj = self.gt_handle.dataobj\n",
    "\n",
    "        if slice_axis not in [0, 1, 2]:\n",
    "            raise RuntimeError(\"Invalid axis, must be between 0 and 2.\")\n",
    "\n",
    "        if slice_axis == 2:\n",
    "            input_slice = np.asarray(input_dataobj[..., slice_index],\n",
    "                                     dtype=np.float32)\n",
    "        elif slice_axis == 1:\n",
    "            input_slice = np.asarray(input_dataobj[:, slice_index, ...],\n",
    "                                     dtype=np.float32)\n",
    "        elif slice_axis == 0:\n",
    "            input_slice = np.asarray(input_dataobj[slice_index, ...],\n",
    "                                     dtype=np.float32)\n",
    "\n",
    "        # Handle the case for unlabeled data\n",
    "        gt_meta_dict = None\n",
    "        if self.gt_handle is None:\n",
    "            gt_slice = None\n",
    "        else:\n",
    "            if slice_axis == 2:\n",
    "                gt_slice = np.asarray(gt_dataobj[..., slice_index],\n",
    "                                      dtype=np.float32)\n",
    "            elif slice_axis == 1:\n",
    "                gt_slice = np.asarray(gt_dataobj[:, slice_index, ...],\n",
    "                                      dtype=np.float32)\n",
    "            elif slice_axis == 0:\n",
    "                gt_slice = np.asarray(gt_dataobj[slice_index, ...],\n",
    "                                      dtype=np.float32)\n",
    "\n",
    "        dreturn = {\n",
    "            \"input\": input_slice,\n",
    "            \"gt\": gt_slice,\n",
    "        }\n",
    "        \n",
    "        return dreturn\n",
    "\n",
    "\n",
    "class MRI2DSegmentationDataset(Dataset):\n",
    "    \"\"\"This is a generic class for 2D (slice-wise) segmentation datasets.\n",
    "\n",
    "    :param filename_pairs: a list of tuples in the format (input filename,\n",
    "                           ground truth filename).\n",
    "    :param slice_axis: axis to make the slicing (default axial).\n",
    "    :param cache: if the data should be cached in memory or not.\n",
    "    :param transform: transformations to apply.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, slice_axis=2, cache=False,\n",
    "                 transform=None, slice_filter_fn=None, canonical=False):\n",
    "\n",
    "        self.data_dir = data_dir\n",
    "        self.pt_path,self.mask_path = get_path_modality_and_mask(self.data_dir)\n",
    "        self.masks_dir = [dir_mask for dir_mask in os.listdir(self.data_dir) if 'masks' in dir_mask] \n",
    "\n",
    "        self.filename_pairs = [(p_pt,p_mask) for p_pt,p_mask in zip(self.pt_path,self.mask_path)]\n",
    "  \n",
    "        self.handlers = []\n",
    "        self.indexes = []\n",
    "        self.transform = transform\n",
    "        self.cache = cache\n",
    "        self.slice_axis = slice_axis\n",
    "        self.slice_filter_fn = slice_filter_fn\n",
    "        self.canonical = canonical\n",
    "\n",
    "        self._load_filenames()\n",
    "        self._prepare_indexes()\n",
    "\n",
    "    def _load_filenames(self):\n",
    "        for input_filename, gt_filename in self.filename_pairs:\n",
    "            segpair = SegmentationPair2D(input_filename, gt_filename.replace('PET0_masks',str(self.masks_dir[np.random.randint(len(self.masks_dir))])),self.cache, self.canonical)\n",
    "            self.handlers.append(segpair)\n",
    "        \n",
    "    def _prepare_indexes(self):\n",
    "        for segpair in self.handlers:\n",
    "            input_data_shape, _ = segpair.get_pair_shapes()\n",
    "            for segpair_slice in range(input_data_shape[1]):\n",
    "\n",
    "                # Check if slice pair should be used or not\n",
    "                if self.slice_filter_fn:\n",
    "                    slice_pair = segpair.get_pair_slice(segpair_slice,\n",
    "                                                        self.slice_axis)\n",
    "                    \n",
    "                    filter_fn_ret = self.slice_filter_fn(slice_pair)\n",
    "                    if not filter_fn_ret:\n",
    "                        continue\n",
    "\n",
    "                item = (segpair, segpair_slice)\n",
    "                self.indexes.append(item)\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        \"\"\"This method will replace the current transformation for the\n",
    "        dataset.\n",
    "\n",
    "        :param transform: the new transformation\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the dataset size.\"\"\"\n",
    "        return len(self.indexes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Return the specific index pair slices (input, ground truth).\n",
    "\n",
    "        :param index: slice index.\n",
    "        \"\"\"\n",
    "        segpair, segpair_slice = self.indexes[index]\n",
    "        pair_slice = segpair.get_pair_slice(segpair_slice,\n",
    "                                            self.slice_axis)\n",
    "\n",
    "        pair_slice[\"input\"]=padding((256,256),pair_slice[\"input\"])\n",
    "        pair_slice[\"input\"]/=100\n",
    "        pair_slice[\"gt\"] = (pair_slice['gt']>= 1).astype(np.int)\n",
    "        pair_slice[\"gt\"]=padding((256,256),pair_slice[\"gt\"])\n",
    "#         print(pair_slice[\"gt\"].shape)\n",
    "#         print(pair_slice[\"gt\"].max())\n",
    "        pair_slice[\"gt\"].reshape(256,256)\n",
    "        pair_slice[\"gt\"]=one_hot_encoding(pair_slice[\"gt\"],2)\n",
    "        \n",
    "        # Consistency with torchvision, returning PIL Image\n",
    "        # Using the \"Float mode\" of PIL, the only mode\n",
    "        # supporting unbounded float32 values\n",
    "        input_img = pair_slice[\"input\"]\n",
    "\n",
    "        # Handle unlabeled data\n",
    "        if pair_slice[\"gt\"] is None:\n",
    "            gt_img = None\n",
    "        else:\n",
    "            gt_img = pair_slice[\"gt\"]\n",
    " \n",
    "        data_dict = {\n",
    "            'input': torch.from_numpy(input_img[np.newaxis]).float(),\n",
    "            'gt': torch.from_numpy(gt_img).float(),\n",
    "        }\n",
    "\n",
    "        if self.transform is not None:\n",
    "            data_dict = self.transform(data_dict)\n",
    "\n",
    "        return data_dict\n",
    "\n",
    "data_dir='/media/hmn-mednuc/InternalDisk_1/datasets/GAINED/resampled_croped/'\n",
    "#train_dataset = MRI2DSegmentationDataset(data_dir=data_dir, slice_axis=1,transform=mt_transforms.ToTensor())\n",
    "# train_dataset = MRI2DSegmentationDataset(data_dir=data_dir, slice_axis=1)\n",
    "\n",
    "# print(len(train_dataset))\n",
    "\n",
    "# data = train_dataset[71]\n",
    "# #print(data[\"input\"].shape)\n",
    "# #print(data[\"gt\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MRI2DSegmentationDataset(data_dir=data_dir, slice_axis=1)\n",
    "train_loader,val_loader=prepare_loader(dataset,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([int(len(train_dataset)*0.8),int(len(train_dataset)*0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_split(train_dataset,[int(len(train_dataset)*0.8),int(len(train_dataset)*0.2)+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data['input'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[\"gt\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(all_pt_img[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(all_mask_img[71])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,batch in enumerate(dataloader):\n",
    "    print(batch['gt'].shape)\n",
    "    print(batch['input'].shape)\n",
    "    if i == 75:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,batch in enumerate(train_loader):\n",
    "    gt=batch['input']\n",
    "    for item in gt:\n",
    "        item = item.clone().cpu().detach().numpy()\n",
    "        \n",
    "        plt.imshow(item[0])\n",
    "        plt.show()\n",
    "    if i == 75:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,batch in enumerate(train_loader):\n",
    "    gt=batch['gt']\n",
    "    for item in gt:\n",
    "        plt.imshow(item.squeeze(0)[0],cmap = 'gray')\n",
    "        plt.show()\n",
    "    if i == 75:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,batch in enumerate(train_loader):\n",
    "    gt=batch['gt']\n",
    "    for item in gt:\n",
    "        plt.imshow(item.squeeze(0)[0],cmap = 'gray')\n",
    "        plt.show()\n",
    "    if i == 75:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,batch in enumerate(train_loader):\n",
    "    gt=batch['gt']\n",
    "    for item in gt:\n",
    "        plt.imshow(item.squeeze(0)[0],cmap = 'gray')\n",
    "        plt.show()\n",
    "    if i == 75:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,batch in enumerate(train_loader):\n",
    "    gt=batch['gt']\n",
    "    for item in gt:\n",
    "        plt.imshow(item.squeeze(0)[0],cmap = 'gray')\n",
    "        plt.show()\n",
    "    if i == 75:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python361064bitpytorchconda2a37e9aabdba449990e12aaef5185825"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
